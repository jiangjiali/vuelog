title: 双通道-联合立体声-立体声
------------------------------------
<!-- zh-CN:+ -->
## Dual channel - 双通道
由两个单声道组成，两个声道编码时不考虑相关性，每个声道的码率为音频总码率的一半。例如：在一个128kbits文件里每个声道64kbits。

## Stereo - 立体声
由两个或多个相互独立的声道组成，每个声道的码率根据其各自编码信息量大小而定。人耳听到时能对音源位置进行定位。例如： 在128kbits音频文件里，右边使用48kbits和左边使用96kbits。不会计算双声道之间的资料相关性，但是会协调分配双声道的资料流量，自动分配较多的Bit给复杂的声道使用。

## Joint stereo - 立体声联合
也是由两个声道组成，但编码时兼顾了这两个声道的共同信息量，比Stereo的压缩率更高。在这个压缩模式下，LAME会利用双声道之间的资料相关性进行演算。左右声道资料类似时，会利用M/S(Mid/Side)编码技术，计算中央声道(L+R)和两侧声道差异(L-R)的值，并且会分配较多的Bit给中央声道，增加资料记录频宽。

## 单、双声道
指的是音频处理系统电路是1、2套。

## 立体声
指的是音源。最基本的立体声要求两个发音器件，使得发出的声音被人耳听到后产生立体感。

实现立体声就要求播放器至少具有双声道，音源左右声道分别馈入双声道放大电路最终通过扬声器播放出来。

## 音频数字化
是将连续的模拟声音波形数字化，主要包括采样频率、采样数位/采样精度两方面，二者决定了数字化音频的质量。反映音频数字化质量的另一个重要因素是声道个数。记录声音时，如果每次生成一个声波数据，称为单声道；每次生成二个声波数据，称为立体声（即双声道），立体声能够更真实反映人的听觉感受。

立体声不等于双声道，通俗的介绍应该是立体声一定由双声道组成，但是双声道不一定是立体声，因为立体声是根据双耳效应原理进行录制的，如果一个单声道音源分为两个声道也不能称为立体声，立体声的特点是能够对声音进行左右定位。

在放声系统中，应用两个或两个以上的声音通道，使听者所感到的声源相对空间位置能接近实际声源的相对空间位置，这种重放声音称为立体声。立体声有双声道立体声、四声道立体声、杜比立体声、杜比环绕声、杜比AC-3数码环绕声等。

Joint Stereo是一种立体声编码技巧，主要分为Intensity Stereo(IS)和Mid/Side (M/S) Stereo两种。IS的是在比较低流量时使用，利用了人耳对於低频讯号指向性分辨能力的不足，将音讯资料中的低频分解出来合成单声道资料，剩余的高频资料则合成另一个单声道资料，并另外纪录高频资料的位置资讯，来重建立体声的效果。例如钢琴独奏的录音就可以利用这种方法在有限的资料流量中减少音场资讯却大幅增加音色资讯。

Mid/Side(M/S) Stereo在左右声道资料相似度大时常被用到，纪录方式是将左右声道音讯合并(L+R)得到新的一轨，再将左右声道音讯相减(L-R)得到另外一轨，然后再将这两轨资料用上面提到听觉心理学模型与滤波器处理。Mid/Side(M/S) Stereo与IS一样的是利用部分相位(phase)资讯的损失来换得较高的音色纪录资讯。一般的MP3是Mid/Side Stereo和Intensity Stereo交替使用的，视资料内容与流量而定。如果是更高流量如160kbps以上的MP3，则可以单独将立体声的两个声道独立编码，以保存相位资讯。

## 经过查证得以下结论，仅供参考：
“联合立体声模式”是音频编码的立体声模式之一。联合立体声模式充分利用左右声道的相似之处，对于左右声道的相同部分不再重复编码，减少了数据的浪费，这样就可以做到在较低的位率下表现更丰富的细节。对于左右声道差异不大的音频来说，联合立体声编码模式通常在较低的位率下就可以得到不错的效果。

而“立体声模式”则使用两个相互独立的声道进行编码，因此它需要较多的位率，但它的左右声道的分离度较高，通常使用在位率较高的场合，用于高质量的音频编码。

根据经验，在制作一般的MP3歌曲时，使用128kbit/s的位率和联合立体声模式比较合适。
<!-- zh-CN:- -->

<!-- en-US:+ -->
## Dual channel
It consists of two mono channels, and the correlation is not considered when encoding the two channels. The bit rate of each channel is half of the total audio bit rate. For example: 64kbits per channel in a 128kbits file.

## Stereo
It is composed of two or more independent channels, and the code rate of each channel is determined according to the size of its respective coded information. The human ear can locate the sound source when hearing it. For example: In a 128kbits audio file, use 48kbits on the right and 96kbits on the left. The data correlation between the two channels will not be calculated, but the data traffic of the two channels will be coordinated and allocated, and more Bits will be automatically allocated to the use of complex channels.

## Joint stereo
It is also composed of two channels, but the common information of the two channels is taken into account when encoding, and the compression rate is higher than that of Stereo. In this compression mode, LAME will use the data correlation between the two channels for calculation. When the left and right channel data are similar, the M/S (Mid/Side) coding technology will be used to calculate the center channel (L+R) and the side channel difference (LR) values, and more Bits will be allocated to the center Channel, increase the data recording bandwidth.

## Single and dual channel
Refers to the audio processing system circuit is 1, 2 sets.

## Stereo
Refers to the sound source. The most basic stereo requires two sounding devices, so that the sound produced by the human ear produces a three-dimensional effect.

The realization of stereo sound requires the player to have at least two channels, and the left and right channels of the audio source are respectively fed into the two-channel amplifier circuit and finally played out through the speakers.

## Audio Digitization
It is to digitize the continuous analog sound waveform, mainly including sampling frequency, sampling digit/sampling accuracy, both of which determine the quality of digitized audio. Another important factor that reflects the quality of audio digitization is the number of channels. When recording sound, if one sound wave data is generated each time, it is called mono; each time two sound wave data is generated, it is called stereo (that is, two channels). Stereo can more truly reflect the human hearing experience.

Stereo is not equal to two channels. The popular introduction should be that stereo must be composed of two channels, but two channels are not necessarily stereo, because stereo is recorded according to the principle of binaural effect, if a mono sound source is divided into two A channel cannot be called stereo either. The characteristic of stereo is the ability to position the sound left and right.

In the sound reproduction system, two or more sound channels are used to make the relative spatial position of the sound source felt by the listener close to the relative spatial position of the actual sound source. This kind of reproduced sound is called stereo. Stereo has two-channel stereo, four-channel stereo, Dolby stereo, Dolby surround sound, Dolby AC-3 digital surround sound and so on.

Joint Stereo is a stereo coding technique, mainly divided into Intensity Stereo (IS) and Mid/Side (M/S) Stereo. IS is used at relatively low traffic. It takes advantage of the lack of human ears' ability to distinguish the directivity of low-frequency signals. The low-frequency of the audio data is decomposed into monophonic data, and the remaining high-frequency data is synthesized into another monophonic sound. Channel data, and additionally record the position information of the high-frequency data to reconstruct the stereo effect. For example, the recording of piano solo can use this method to reduce the sound field information but greatly increase the timbre information in the limited data flow.

Mid/Side(M/S) Stereo is often used when the left and right channel data is very similar. The recording method is to combine the left and right channel audio (L+R) to get a new track, and then subtract the left and right channel audio. (LR) Get another track, and then process the two tracks with the aforementioned auditory psychology model and filter. Mid/Side(M/S) Stereo, like IS, uses the loss of some phase information in exchange for higher tone record information. General MP3 is used alternately between Mid/Side Stereo and Intensity Stereo, depending on the content of the data and traffic. If it is a higher flow rate such as MP3 above 160kbps, the two stereo channels can be encoded independently to save the phase information.

## After verification, the following conclusions are obtained, for reference only:
"Joint Stereo Mode" is one of the stereo modes of audio coding. The joint stereo mode makes full use of the similarities between the left and right channels, and does not re-encode the same parts of the left and right channels, reducing data waste, so that it can achieve richer details at a lower bit rate. For audio with little difference between the left and right channels, the joint stereo coding mode usually can get good results at a lower bit rate.

The "stereo mode" uses two independent channels for encoding, so it needs more bit rate, but its left and right channels have a higher degree of separation. It is usually used in higher bit rate occasions. High-quality audio coding.

According to experience, when making general MP3 songs, it is more appropriate to use 128kbit/s bit rate and joint stereo mode.
<!-- en-US:- -->